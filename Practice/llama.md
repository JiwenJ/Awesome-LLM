

#### Why should we or must we finetune our model?

Steer the output

reduce hallucination

 



#### Data Preparation



#### Computation consuming calculation





#### Finetuning

- Full training
- PEFT
- Lora



#### Evaluation

#### Benchmark





#### Open source model

#### Meta Llama Series

- Llama
- Llama2
- CodeLlma





### Deployment

#### LLaMA

- æ¨¡åž‹çš„æŽ¨ç†

  - text-generation-webui

    - ```python
      python server.py --model llama1_13b_hf --api --listen --public-api --gpu-memory 20 20 20
      ```

  - fastchat

  - vLLM

  - transformer libs

#### LLaMA 2

- æ•°æ®å‡†å¤‡
- GPUå’Œå†…å­˜å‡†å¤‡
  - 7B 13G
  - 13B 
- æ¨¡åž‹çš„è½¬æ¢ï¼Œå› ä¸ºä½¿ç”¨text-gui-
  - [huggingface/transformers: ðŸ¤— Transformers: State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX. (github.com)](https://github.com/huggingface/transformers)
  - [LLama 2å¹²è´§éƒ¨ç½²æ•™ç¨‹+æ¨¡åž‹åˆ†å‘ - çŸ¥ä¹Ž (zhihu.com)](https://zhuanlan.zhihu.com/p/645142694)	

```python
	python src/transformers/models/llama/convert_llama_weights_to_hf.py --input_dir ../13B --model_size 13B --output_dir ../llama1_13b_hf
```

- æ¨¡åž‹çš„æŽ¨ç†

  - transformer library

    - é€‰å–æœ¬åœ°æ–‡ä»¶

  - text-generation-webui

    - [text-generation-webui](https://link.zhihu.com/?target=https%3A//github.com/oobabooga/text-generation-webui.git)
  
    - [oobabooga/text-generation-webui: A Gradio web UI for Large Language Models. Supports transformers, GPTQ, llama.cpp (GGUF), Llama models. (github.com)](https://github.com/oobabooga/text-generation-webui)

    - 
  
    - ```python
      python server.py --model  --api --listen --public-api
      ```
  
  - fastchat
  







#### library

> - lamini
> - pytorch
> - huggingface
> - [ä½¿ç”¨ FastChat éƒ¨ç½² LLM - Hacker and Geeker's Way (zhaozhiming.github.io)](https://zhaozhiming.github.io/2023/08/22/use-fastchat-deploy-llm/)



[ä½¿ç”¨ FastChat éƒ¨ç½² LLM - Hacker and Geeker's Way (zhaozhiming.github.io)](https://zhaozhiming.github.io/2023/08/22/use-fastchat-deploy-llm/)

https://github.com/oobabooga/text-generation-webui/blob/main/docs/LLaMA-v2-model.md

https://zhuanlan.zhihu.com/p/645142694

https://github.com/ggerganov/llama.cpp#prepare-data--run

https://huggingface.co/blog/llama2#using-transformers

[huggingface AutoTokenizer.from_pretrainedæµç¨‹ - çŸ¥ä¹Ž (zhihu.com)](https://zhuanlan.zhihu.com/p/621106604)

[åŠŸèƒ½è¶…å…¨çš„å¼ºåŒ–å­¦ä¹ ç”»å›¾è„šæœ¬ - çŸ¥ä¹Ž (zhihu.com)](https://zhuanlan.zhihu.com/p/362677143#:~:text=å¯ä»¥ç›´æŽ¥åœ¨pycharmæˆ–è€…vscodeæ‰§è¡Œï¼Œä¹Ÿå¯ä»¥ç”¨å‘½ä»¤è¡Œä¼ å‚ï¼› æŒ‰exp_nameæŽ’åºï¼Œè€Œä¸æ˜¯æŒ‰æ—¶é—´æŽ’åºï¼›,å›ºå®šå¥½æ¯ä¸ªexp_nameçš„é¢œè‰²ï¼› å¯ä»¥è°ƒèŠ‚æ›²çº¿çš„çº¿å®½ï¼Œä¾¿äºŽè§‚å¯Ÿï¼› ä¿å­˜å›¾ç‰‡åˆ°æœ¬åœ°ï¼Œä¾¿äºŽè¿œç¨‹sshç”»å›¾~)

#### Reference



> - https://ai.meta.com/llama/
> - https://huggingface.co/meta-llama
> - https://ai.meta.com/blog/code-llama-large-language-model-coding/?utm_source=twitter&utm_medium=organic_social&utm_campaign=codellama&utm_content=image
> - https://openrouter.ai/playground
> - https://github.com/openai/openai-cookbook/blob/main/examples/How_to_stream_completions.ipynb
> - https://medium.com/@alonso.silva/how-to-access-gpt-4-gpt4-32k-right-now-for-4-dollars-pay-as-you-go-1ce4b0d7cee6
> - https://gptgod.site/#/forgot
> - https://github.com/lamini-ai/lamini
> - https://app.lamini.ai/account

